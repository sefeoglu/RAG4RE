{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christoph/.miniconda3/envs/tacrev/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "from tacrev.analysis import true_pred_labels_from_dataframe\n",
    "from tacrev.readers.tacred import load_tacred\n",
    "from tacrev.readers.evaluation_results import load_evaluation_results\n",
    "from tacrev.writers.writer_utils import results_as_dataframe, documents_as_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_end(text, suffixes):\n",
    "    for suffix in suffixes:\n",
    "        if not text.endswith(suffix):\n",
    "            text = text\n",
    "            continue\n",
    "        \n",
    "        text = text[:len(text)-len(suffix)]\n",
    "    return text\n",
    "\n",
    "\n",
    "def ensemble_p_r_f1_score_as_df(dataframe, true_label_col, ignore_models: List[str] = None, ignore_label=\"no_relation\", average=\"micro\", sample_weight=None):\n",
    "    ignore_models = ignore_models or []\n",
    "    \n",
    "    true_labels = dataframe[true_label_col]\n",
    "    \n",
    "    pred_labels = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        preds = []\n",
    "        for model_name, pred in row[\"model_pred\"].items():\n",
    "            if any([s in model_name.lower() for s in ignore_models]):\n",
    "                continue\n",
    "            preds.append(pred)\n",
    "        pred_labels.append(Counter(preds).most_common()[0][0])\n",
    "    \n",
    "    dataframe[\"pred_label\"]\n",
    "    \n",
    "    \n",
    "    unique_labels = list(set(true_labels) | set(pred_labels))\n",
    "    \n",
    "    if ignore_label and ignore_label in unique_labels:\n",
    "        unique_labels.remove(ignore_label)\n",
    "    \n",
    "    \n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(true_labels,\n",
    "                                                       pred_labels,\n",
    "                                                       labels=unique_labels,\n",
    "                                                       average=average,\n",
    "                                                       sample_weight=sample_weight)\n",
    "        \n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def p_r_f1_scores_as_df(dataframe, models, true_label_col, ignore_label=\"no_relation\", average=\"micro\", sample_weight=None):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    for model_name in models:\n",
    "        true_labels, pred_labels, unique_labels = true_pred_labels_from_dataframe(dataframe,\n",
    "                                                                                  ignore_label,\n",
    "                                                                                  true_label_col,\n",
    "                                                                                  model_name)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(true_labels,\n",
    "                                                           pred_labels,\n",
    "                                                           labels=unique_labels,\n",
    "                                                           average=average,\n",
    "                                                           sample_weight=sample_weight)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "        \n",
    "    return precisions, recalls, f1s\n",
    "\n",
    "\n",
    "def p_r_f1_orig_enhanced_weighted_as_df(dataframe,\n",
    "                                        models,\n",
    "                                        split,\n",
    "                                        model_name_map=None,\n",
    "                                        to_percentage: bool=True,\n",
    "                                        average=\"micro\"):\n",
    "    model_name_map = model_name_map or {}\n",
    "    \n",
    "    sample_weight = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        num_incorrect = 0\n",
    "        num_all = 0\n",
    "        for model_name, pred in row[\"model_pred\"].items():\n",
    "            if any([s in model_name.lower() for s in [\"tre\", \"spanbert\", \"knowbert\"]]):\n",
    "                continue\n",
    "                \n",
    "            num_all += 1\n",
    "            if pred != row[\"true_label_reannotated\"]:\n",
    "                num_incorrect += 1\n",
    "                \n",
    "        sample_weight.append(num_incorrect / float(num_all))\n",
    "    \n",
    "    models_w_split = [f\"{m}_{split}\" for m in models]\n",
    "    \n",
    "    prec_orig, rec_orig, f1_orig = p_r_f1_scores_as_df(dataframe, models_w_split,\n",
    "                                                       true_label_col=\"true_label\",\n",
    "                                                       ignore_label=\"no_relation\",\n",
    "                                                       average=average)\n",
    "    \n",
    "    prec_enh, rec_enh, f1_enh = p_r_f1_scores_as_df(dataframe, models_w_split,\n",
    "                                                    true_label_col=\"true_label_reannotated\",\n",
    "                                                    ignore_label=\"no_relation\",\n",
    "                                                    average=average)\n",
    "    \n",
    "    prec_weight, rec_weight, f1_weight = p_r_f1_scores_as_df(dataframe, models_w_split,\n",
    "                                                             true_label_col=\"true_label_reannotated\",\n",
    "                                                             ignore_label=\"no_relation\",\n",
    "                                                             average=average,\n",
    "                                                             sample_weight=sample_weight)\n",
    "    \n",
    "    df = pd.DataFrame([prec_orig, rec_orig, f1_orig, prec_enh, rec_enh, f1_enh, prec_weight, rec_weight, f1_weight]).T\n",
    "    df[\"Model\"] = [model_name_map.get(m, m) for m in models]\n",
    "    df = df.set_index(\"Model\")\n",
    "    df.columns = pd.MultiIndex.from_product([[\"Original\", \"Revised\", \"Weighted\"], [\"P\", \"R\", \"F1\"]])\n",
    "    \n",
    "    if to_percentage:\n",
    "        df = df.apply(lambda x: x * 100)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def p_r_f1_orig_enhanced_as_df(dataframe,\n",
    "                               models,\n",
    "                               split,\n",
    "                               model_name_map=None,\n",
    "                               to_percentage: bool=True,\n",
    "                               average=\"micro\"):\n",
    "    model_name_map = model_name_map or {}\n",
    "    \n",
    "    sample_weight = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        num_incorrect = 0\n",
    "        num_all = 0\n",
    "        for model_name, pred in row[\"model_pred\"].items():\n",
    "            if any([s in model_name.lower() for s in [\"tre\", \"spanbert\", \"knowbert\"]]):\n",
    "                continue\n",
    "                \n",
    "            num_all += 1\n",
    "            if pred != row[\"true_label_reannotated\"]:\n",
    "                num_incorrect += 1\n",
    "                \n",
    "        sample_weight.append(num_incorrect / float(num_all))\n",
    "    \n",
    "    models_w_split = [f\"{m}_{split}\" for m in models]\n",
    "    \n",
    "    prec_orig, rec_orig, f1_orig = p_r_f1_scores_as_df(dataframe, models_w_split,\n",
    "                                                       true_label_col=\"true_label\",\n",
    "                                                       ignore_label=\"no_relation\",\n",
    "                                                       average=average)\n",
    "    \n",
    "    prec_enh, rec_enh, f1_enh = p_r_f1_scores_as_df(dataframe, models_w_split,\n",
    "                                                    true_label_col=\"true_label_reannotated\",\n",
    "                                                    ignore_label=\"no_relation\",\n",
    "                                                    average=average)\n",
    "    \n",
    "    df = pd.DataFrame([prec_orig, rec_orig, f1_orig, prec_enh, rec_enh, f1_enh]).T\n",
    "    df[\"Model\"] = [model_name_map.get(m, m) for m in models]\n",
    "    df = df.set_index(\"Model\")\n",
    "    df.columns = pd.MultiIndex.from_product([[\"Original\", \"Revised\"], [\"P\", \"R\", \"F1\"]])\n",
    "    \n",
    "    if to_percentage:\n",
    "        df = df.apply(lambda x: x * 100)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def f1_orig_enhanced_weighted_as_df(dataframe,\n",
    "                                    models,\n",
    "                                    split,\n",
    "                                    model_name_map=None,\n",
    "                                    to_percentage: bool=True,\n",
    "                                    average=\"micro\"):\n",
    "    model_name_map = model_name_map or {}\n",
    "    \n",
    "    sample_weight = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        num_incorrect = 0\n",
    "        num_all = 0\n",
    "        for model_name, pred in row[\"model_pred\"].items():\n",
    "            if any([s in model_name.lower() for s in [\"tre\", \"spanbert\", \"knowbert\"]]):\n",
    "                continue\n",
    "                \n",
    "            num_all += 1\n",
    "            if pred != row[\"true_label_reannotated\"]:\n",
    "                num_incorrect += 1\n",
    "                \n",
    "        sample_weight.append(num_incorrect / float(num_all))\n",
    "    \n",
    "    models_w_split = [f\"{m}_{split}\" for m in models]\n",
    "    \n",
    "    prec_orig, rec_orig, f1_orig = p_r_f1_scores_as_df(dataframe, models_w_split,\n",
    "                                                       true_label_col=\"true_label\",\n",
    "                                                       ignore_label=\"no_relation\",\n",
    "                                                       average=average)\n",
    "    \n",
    "    prec_enh, rec_enh, f1_enh = p_r_f1_scores_as_df(dataframe, models_w_split,\n",
    "                                                    true_label_col=\"true_label_reannotated\",\n",
    "                                                    ignore_label=\"no_relation\",\n",
    "                                                    average=average)\n",
    "    \n",
    "    prec_weight, rec_weight, f1_weight = p_r_f1_scores_as_df(dataframe, models_w_split,\n",
    "                                                             true_label_col=\"true_label_reannotated\",\n",
    "                                                             ignore_label=\"no_relation\",\n",
    "                                                             average=average,\n",
    "                                                             sample_weight=sample_weight)\n",
    "    \n",
    "    df = pd.DataFrame([f1_orig, f1_enh, f1_weight]).T\n",
    "    df[\"Model\"] = [model_name_map.get(m, m) for m in models]\n",
    "    df = df.set_index(\"Model\")\n",
    "    df.columns = pd.MultiIndex.from_product([[\"Original\", \"Revised\", \"Weighted\"], [\"F1\"]])\n",
    "    \n",
    "    if to_percentage:\n",
    "        df = df.apply(lambda x: x * 100)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../dataset/test_rev.json\"\n",
    "MODEL_RESULTS_PATH = \"../results/test_results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_UNDER_INVESTIGATION = [\"cnn_wo_discr_masked\",\n",
    "                              \"tre_tacred\",\n",
    "                              \"spanbert_tacred\",\n",
    "                              \"knowbert_wordnet_wiki_tacred\"]\n",
    "\n",
    "MODEL_NAME_MAP = {\n",
    "    \"cnn_wo_discr_unmasked\": \"CNN\",\n",
    "    \"cnn_wo_discr_masked\": \"CNN, masked\",\n",
    "    \"self_att_wo_discr_unmasked\": \"S-Att.\",\n",
    "    \"self_att_wo_discr_masked\": \"S-Att., masked\",\n",
    "    \"tre_tacred\": \"TRE\",\n",
    "    \"spanbert_tacred\": \"SpanBERT\",\n",
    "    \"knowbert_wordnet_wiki_tacred\": \"KnowBert-W+W\"\n",
    "}\n",
    "\n",
    "ENSEMBLE_MODEL_NAME_MAP = {\n",
    "    \"bag_of_embeddings\": \"BoE\",\n",
    "\n",
    "    \"cnn_wo_discr_unmasked\": \"CNN\",\n",
    "    \"cnn_wo_discr_masked\": \"CNN, masked\",\n",
    "    \"cnn\": \"CNN w/ synt/sem\",\n",
    "    \n",
    "    \"cnn_elmo_wo_discr_unmasked\": \"CNN + ELMo\",\n",
    "    \"cnn_elmo_wo_discr_masked\": \"CNN + ELMo, masked\",\n",
    "    \"cnn_elmo\": \"CNN + ELMo, masked w/ synt/sem\",\n",
    "    \n",
    "    \"cnn_bert_uncased_unmasked\": \"CNN + BERT uncased\",\n",
    "    \"cnn_bert_uncased\": \"CNN + BERT uncased, masked\",\n",
    "    \"cnn_bert_cased_unmasked\": \"CNN + BERT cased\",\n",
    "    \"cnn_bert_cased\": \"CNN + BERT cased, masked\",\n",
    "\n",
    "    \n",
    "    \"lstm_wo_discr_unmasked\": \"LSTM\",\n",
    "    \"lstm_wo_discr_masked\": \"LSTM, masked\",\n",
    "    \"lstm\": \"LSTM, masked w/ synt/sem\",\n",
    "    \n",
    "    \"lstm_elmo_wo_discr_unmasked\": \"LSTM + ELMo\",\n",
    "    \"lstm_elmo_wo_discr_masked\": \"LSTM + ELMo, masked\",\n",
    "    \"lstm_elmo\": \"LSTM + ELMo, masked w/ synt/sem\",\n",
    "    \n",
    "    \"lstm_bert_uncased_unmasked\": \"LSTM + BERT uncased\",\n",
    "    \"lstm_bert_uncased\": \"LSTM + BERT uncased, masked\",\n",
    "    \"lstm_bert_cased_unmasked\": \"LSTM + BERT cased\",\n",
    "    \"lstm_bert_cased\": \"LSTM + BERT cased, masked\",\n",
    "\n",
    "    \n",
    "    \"bilstm_wo_discr_unmasked\": \"Bi-LSTM\",\n",
    "    \"bilstm_wo_discr_masked\": \"Bi-LSTM, masked\",\n",
    "    \n",
    "    \"bilstm_elmo_wo_discr_unmasked\": \"Bi-LSTM + ELMo\",\n",
    "    \"bilstm_elmo_wo_discr_masked\": \"Bi-LSTM + ELMo, masked\",\n",
    "    \"bilstm_elmo_unmasked\": \"Bi-LSTM + ELMo w/ synt/sem\",\n",
    "    \"bilstm_elmo\": \"Bi-LSTM + ELMo, masked w/ synt/sem\",\n",
    "    \n",
    "    \"bilstm_bert_uncased_unmasked\": \"Bi-LSTM + BERT uncased\",\n",
    "    \"bilstm_bert_uncased\": \"Bi-LSTM + BERT uncased, masked\",\n",
    "    \"bilstm_bert_cased_unmasked\": \"Bi-LSTM + BERT cased\",\n",
    "    \"bilstm_bert_cased\": \"Bi-LSTM + BERT cased, masked\",\n",
    "    \n",
    "    \n",
    "    \"gcn_wo_discr_unmasked\": \"GCN\",\n",
    "    \"gcn_wo_discr_masked\": \"GCN, masked\",\n",
    "    \"gcn\": \"GCN, masked w/ synt/sem\",\n",
    "    \n",
    "    \"gcn_elmo_wo_discr_unmasked\": \"GCN + ELMo\",\n",
    "    \"gcn_elmo_wo_discr_masked\": \"GCN + ELMo, masked\",\n",
    "    \"gcn_elmo\": \"GCN + ELMo, masked w/ synt/sem\",\n",
    "    \n",
    "    \"gcn_bert_uncased_unmasked\": \"GCN + BERT uncased\",\n",
    "    \"gcn_bert_uncased\": \"GCN + BERT uncased, masked\",\n",
    "    \"gcn_bert_cased_unmasked\": \"GCN + BERT cased\",\n",
    "    \"gcn_bert_cased\": \"GCN + BERT cased, masked\",\n",
    "\n",
    "    \n",
    "    \"self_att_wo_discr_unmasked\": \"S-Att.\",\n",
    "    \"self_att_wo_discr_masked\": \"S-Att., masked\",\n",
    "    \n",
    "    \"self_att_elmo_wo_discr_unmasked\": \"S-Att. + ELMo\",\n",
    "    \"self_att_elmo_wo_discr_masked\": \"S-Att. + ELMo, masked\",\n",
    "    \n",
    "    \"self_att_bert_uncased_unmasked\": \"S-Att. + BERT uncased\",\n",
    "    \"self_att_bert_uncased\": \"S-Att. + BERT uncased, masked\",\n",
    "    \"self_att_bert_cased_unmasked\": \"S-Att. + BERT cased\",\n",
    "    \"self_att_bert_cased\": \"S-Att. + BERT cased, masked\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bilstm_elmo_unmasked'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENSEMBLE_MODEL_NAME_MAP.keys() - ENSEMBLE_MODEL_NAME_MAP_SHORT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_tacred(DATASET_PATH)\n",
    "documents_df = documents_as_dataframe(documents, mark_arguments=True)\n",
    "evaluation_results = results_as_dataframe(load_evaluation_results(MODEL_RESULTS_PATH, documents))\n",
    "combined_df = pd.merge(documents_df, evaluation_results, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 score for TACRED, revised TACRED, and difficulty weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{c}{Original} & \\multicolumn{3}{c}{Revised} & \\multicolumn{3}{c}{Weighted} \\\\\n",
      "{} &        P &    R &   F1 &       P &    R &   F1 &        P &    R &   F1 \\\\\n",
      "Model        &          &      &      &         &      &      &          &      &      \\\\\n",
      "\\midrule\n",
      "CNN, masked  & 67.2 & 53.5 & 59.5 & 72.5 & 61.4 & 66.5 & 47.5 & 27.5 & 34.8 \\\\\n",
      "TRE          & 70.1 & 65.0 & 67.4 & 75.8 & 74.9 & 75.3 & 54.8 & 43.9 & 48.8 \\\\\n",
      "SpanBERT     & 70.8 & 70.9 & 70.8 & 75.6 & 80.6 & 78.0 & 65.0 & 59.0 & 61.9 \\\\\n",
      "KnowBert-W+W & 71.4 & 71.6 & 71.5 & 76.8 & 82.0 & 79.3 & 61.6 & 55.9 & 58.7 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p_r_f1_orig_enhanced_weighted_as_df(combined_df,\n",
    "                                          split=\"test\",\n",
    "                                          models=MODELS_UNDER_INVESTIGATION,\n",
    "                                          model_name_map=MODEL_NAME_MAP).to_latex(float_format=\"{:0.1f}\".format, multicolumn_format=\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Original</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Revised</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN, masked</th>\n",
       "      <td>67.170382</td>\n",
       "      <td>53.473684</td>\n",
       "      <td>59.544541</td>\n",
       "      <td>72.459388</td>\n",
       "      <td>61.415306</td>\n",
       "      <td>66.481802</td>\n",
       "      <td>47.478745</td>\n",
       "      <td>27.480009</td>\n",
       "      <td>34.811581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRE</th>\n",
       "      <td>70.061628</td>\n",
       "      <td>64.962406</td>\n",
       "      <td>67.415730</td>\n",
       "      <td>75.835225</td>\n",
       "      <td>74.863913</td>\n",
       "      <td>75.346439</td>\n",
       "      <td>54.842468</td>\n",
       "      <td>43.934927</td>\n",
       "      <td>48.786462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpanBERT</th>\n",
       "      <td>70.793269</td>\n",
       "      <td>70.857143</td>\n",
       "      <td>70.825192</td>\n",
       "      <td>75.600962</td>\n",
       "      <td>80.563561</td>\n",
       "      <td>78.003410</td>\n",
       "      <td>65.006424</td>\n",
       "      <td>59.019662</td>\n",
       "      <td>61.868552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KnowBert-W+W</th>\n",
       "      <td>71.437144</td>\n",
       "      <td>71.609023</td>\n",
       "      <td>71.522980</td>\n",
       "      <td>76.837684</td>\n",
       "      <td>82.004483</td>\n",
       "      <td>79.337051</td>\n",
       "      <td>61.647422</td>\n",
       "      <td>55.939933</td>\n",
       "      <td>58.655161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Original                          Revised                         Weighted                      \n",
       "                      P          R         F1          P          R         F1          P          R         F1\n",
       "Model                                                                                                          \n",
       "CNN, masked   67.170382  53.473684  59.544541  72.459388  61.415306  66.481802  47.478745  27.480009  34.811581\n",
       "TRE           70.061628  64.962406  67.415730  75.835225  74.863913  75.346439  54.842468  43.934927  48.786462\n",
       "SpanBERT      70.793269  70.857143  70.825192  75.600962  80.563561  78.003410  65.006424  59.019662  61.868552\n",
       "KnowBert-W+W  71.437144  71.609023  71.522980  76.837684  82.004483  79.337051  61.647422  55.939933  58.655161"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_r_f1_orig_enhanced_weighted_as_df(combined_df,\n",
    "                                    split=\"test\",\n",
    "                                    models=MODELS_UNDER_INVESTIGATION,\n",
    "                                    model_name_map=MODEL_NAME_MAP,\n",
    "                                    average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} & Original & Revised & Weighted \\\\\n",
      "{} &       F1 &      F1 &       F1 \\\\\n",
      "Model        &          &         &          \\\\\n",
      "\\midrule\n",
      "CNN, masked  & 59.5 & 66.5 & 34.8 \\\\\n",
      "TRE          & 67.4 & 75.3 & 48.8 \\\\\n",
      "SpanBERT     & 70.8 & 78.0 & 61.9 \\\\\n",
      "KnowBert-W+W & 71.5 & 79.3 & 58.7 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_orig_enhanced_weighted_as_df(combined_df,\n",
    "                                    split=\"test\",\n",
    "                                    models=MODELS_UNDER_INVESTIGATION,\n",
    "                                    model_name_map=MODEL_NAME_MAP,\n",
    "                                    average=\"micro\").to_latex(float_format=\"{:0.1f}\".format, multicolumn_format=\"c\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble F1 score for TACRED (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7583819241982507, 0.6258646616541353, 0.6857801944307135)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_p_r_f1_score_as_df(combined_df,\n",
    "                            true_label_col=\"true_label\",\n",
    "                            ignore_models=[\"tre\", \"spanbert\", \"knowbert\"],\n",
    "                            ignore_label=\"no_relation\",\n",
    "                            average=\"micro\",\n",
    "                            sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble F1 score for TACRED (revised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8567784256559767, 0.7528017931476145, 0.8014317368331345)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_p_r_f1_score_as_df(combined_df,\n",
    "                            true_label_col=\"true_label_reannotated\",\n",
    "                            ignore_models=[\"tre\", \"spanbert\", \"knowbert\"],\n",
    "                            ignore_label=\"no_relation\",\n",
    "                            average=\"micro\",\n",
    "                            sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{c}{Original} & \\multicolumn{3}{c}{Revised} \\\\\n",
      "{} &        P &    R &   F1 &       P &    R &   F1 \\\\\n",
      "Model                              &          &      &      &         &      &      \\\\\n",
      "\\midrule\n",
      "BoE                                & 50.0 & 32.6 & 39.4 & 51.8 & 35.9 & 42.4 \\\\\n",
      "CNN                                & 72.3 & 45.5 & 55.9 & 79.8 & 53.5 & 64.1 \\\\\n",
      "CNN, masked                        & 67.2 & 53.5 & 59.5 & 72.5 & 61.4 & 66.5 \\\\\n",
      "CNN w/ synt/sem                    & 72.2 & 54.7 & 62.2 & 79.7 & 64.3 & 71.2 \\\\\n",
      "CNN + ELMo                         & 73.8 & 48.8 & 58.8 & 82.1 & 57.9 & 67.9 \\\\\n",
      "CNN + ELMo, masked                 & 72.3 & 53.8 & 61.7 & 79.8 & 63.2 & 70.5 \\\\\n",
      "CNN + ELMo, masked w/ synt/sem     & 69.2 & 59.0 & 63.7 & 76.0 & 69.1 & 72.4 \\\\\n",
      "CNN + BERT uncased                 & 71.9 & 51.1 & 59.7 & 79.5 & 60.2 & 68.5 \\\\\n",
      "CNN + BERT uncased, masked         & 69.0 & 62.0 & 65.3 & 74.9 & 71.7 & 73.2 \\\\\n",
      "CNN + BERT cased                   & 69.7 & 54.3 & 61.0 & 77.6 & 64.3 & 70.4 \\\\\n",
      "CNN + BERT cased, masked           & 71.8 & 61.1 & 66.1 & 78.1 & 70.8 & 74.3 \\\\\n",
      "LSTM                               & 59.3 & 47.5 & 52.7 & 65.9 & 56.2 & 60.6 \\\\\n",
      "LSTM, masked                       & 63.4 & 51.7 & 57.0 & 68.7 & 59.7 & 63.9 \\\\\n",
      "LSTM, masked w/ synt/sem           & 65.4 & 56.8 & 60.8 & 71.2 & 66.0 & 68.5 \\\\\n",
      "LSTM + ELMo                        & 61.5 & 61.3 & 61.4 & 68.1 & 72.2 & 70.1 \\\\\n",
      "LSTM + ELMo, masked                & 63.9 & 64.9 & 64.4 & 69.3 & 75.0 & 72.1 \\\\\n",
      "LSTM + ELMo, masked w/ synt/sem    & 61.7 & 67.8 & 64.6 & 66.1 & 77.3 & 71.2 \\\\\n",
      "LSTM + BERT uncased                & 64.7 & 60.2 & 62.4 & 71.6 & 71.0 & 71.3 \\\\\n",
      "LSTM + BERT uncased, masked        & 65.3 & 64.8 & 65.1 & 70.4 & 74.3 & 72.3 \\\\\n",
      "LSTM + BERT cased                  & 66.2 & 59.8 & 62.8 & 73.5 & 70.8 & 72.1 \\\\\n",
      "LSTM + BERT cased, masked          & 68.9 & 61.9 & 65.2 & 75.0 & 71.8 & 73.4 \\\\\n",
      "Bi-LSTM                            & 53.3 & 57.4 & 55.3 & 58.6 & 67.2 & 62.6 \\\\\n",
      "Bi-LSTM, masked                    & 62.5 & 63.4 & 62.9 & 67.7 & 73.1 & 70.3 \\\\\n",
      "Bi-LSTM + ELMo                     & 65.0 & 58.7 & 61.7 & 72.6 & 69.8 & 71.1 \\\\\n",
      "Bi-LSTM + ELMo, masked             & 63.3 & 64.8 & 64.1 & 68.9 & 75.2 & 71.9 \\\\\n",
      "Bi-LSTM + ELMo w/ synt/sem         & 64.8 & 57.9 & 61.2 & 72.1 & 68.6 & 70.3 \\\\\n",
      "Bi-LSTM + ELMo, masked w/ synt/sem & 63.0 & 65.9 & 64.4 & 67.5 & 75.2 & 71.2 \\\\\n",
      "Bi-LSTM + BERT uncased             & 65.3 & 59.9 & 62.5 & 71.8 & 70.2 & 71.0 \\\\\n",
      "Bi-LSTM + BERT uncased, masked     & 64.9 & 66.0 & 65.4 & 69.6 & 75.3 & 72.4 \\\\\n",
      "Bi-LSTM + BERT cased               & 65.2 & 61.2 & 63.1 & 72.1 & 72.1 & 72.1 \\\\\n",
      "Bi-LSTM + BERT cased, masked       & 68.3 & 64.0 & 66.1 & 74.1 & 73.9 & 74.0 \\\\\n",
      "GCN                                & 65.6 & 50.5 & 57.1 & 72.4 & 59.3 & 65.2 \\\\\n",
      "GCN, masked                        & 68.2 & 58.0 & 62.7 & 74.3 & 67.4 & 70.7 \\\\\n",
      "GCN, masked w/ synt/sem            & 68.6 & 60.2 & 64.2 & 74.2 & 69.3 & 71.7 \\\\\n",
      "GCN + ELMo                         & 66.5 & 57.6 & 61.7 & 73.4 & 67.7 & 70.4 \\\\\n",
      "GCN + ELMo, masked                 & 68.5 & 61.3 & 64.7 & 74.5 & 71.0 & 72.7 \\\\\n",
      "GCN + ELMo, masked w/ synt/sem     & 67.9 & 64.8 & 66.3 & 73.3 & 74.4 & 73.9 \\\\\n",
      "GCN + BERT uncased                 & 66.3 & 58.8 & 62.4 & 73.1 & 69.1 & 71.0 \\\\\n",
      "GCN + BERT uncased, masked         & 68.7 & 64.0 & 66.3 & 74.8 & 74.1 & 74.5 \\\\\n",
      "GCN + BERT cased                   & 66.5 & 56.4 & 61.0 & 74.4 & 67.1 & 70.5 \\\\\n",
      "GCN + BERT cased, masked           & 67.2 & 64.6 & 65.9 & 72.9 & 74.7 & 73.8 \\\\\n",
      "S-Att.                             & 56.9 & 58.3 & 57.6 & 62.2 & 67.8 & 64.9 \\\\\n",
      "S-Att., masked                     & 65.0 & 66.8 & 65.9 & 69.3 & 75.8 & 72.4 \\\\\n",
      "S-Att. + ELMo                      & 64.4 & 65.0 & 64.7 & 71.5 & 76.8 & 74.1 \\\\\n",
      "S-Att. + ELMo, masked              & 64.0 & 69.4 & 66.6 & 68.9 & 79.6 & 73.8 \\\\\n",
      "S-Att. + BERT uncased              & 60.6 & 67.6 & 63.9 & 66.3 & 78.7 & 72.0 \\\\\n",
      "S-Att. + BERT uncased, masked      & 64.0 & 69.7 & 66.7 & 68.9 & 80.0 & 74.0 \\\\\n",
      "S-Att. + BERT cased                & 63.5 & 64.1 & 63.8 & 70.4 & 75.7 & 73.0 \\\\\n",
      "S-Att. + BERT cased, masked        & 69.2 & 64.7 & 66.9 & 75.1 & 74.8 & 75.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(p_r_f1_orig_enhanced_as_df(combined_df,\n",
    "                                 split=\"test\",\n",
    "                                 models=list(ENSEMBLE_MODEL_NAME_MAP.keys()),\n",
    "                                 model_name_map=ENSEMBLE_MODEL_NAME_MAP).to_latex(float_format=\"{:0.1f}\".format, multicolumn_format=\"c\", escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Original</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Revised</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>65.646538</td>\n",
       "      <td>59.476446</td>\n",
       "      <td>62.136173</td>\n",
       "      <td>71.767340</td>\n",
       "      <td>69.190404</td>\n",
       "      <td>70.146273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.583137</td>\n",
       "      <td>6.943285</td>\n",
       "      <td>4.645253</td>\n",
       "      <td>5.405378</td>\n",
       "      <td>7.880614</td>\n",
       "      <td>5.195892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>49.976927</td>\n",
       "      <td>32.571429</td>\n",
       "      <td>39.439184</td>\n",
       "      <td>51.776650</td>\n",
       "      <td>35.926993</td>\n",
       "      <td>42.419660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.913558</td>\n",
       "      <td>56.842105</td>\n",
       "      <td>61.035156</td>\n",
       "      <td>68.916936</td>\n",
       "      <td>67.114954</td>\n",
       "      <td>70.258621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>65.352697</td>\n",
       "      <td>60.240602</td>\n",
       "      <td>62.944162</td>\n",
       "      <td>72.428627</td>\n",
       "      <td>70.797310</td>\n",
       "      <td>71.240962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.642906</td>\n",
       "      <td>64.721805</td>\n",
       "      <td>65.055874</td>\n",
       "      <td>74.470944</td>\n",
       "      <td>74.671790</td>\n",
       "      <td>72.688525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.751135</td>\n",
       "      <td>69.744361</td>\n",
       "      <td>66.863446</td>\n",
       "      <td>82.061762</td>\n",
       "      <td>79.987192</td>\n",
       "      <td>74.963913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Original                          Revised                      \n",
       "               P          R         F1          P          R         F1\n",
       "count  49.000000  49.000000  49.000000  49.000000  49.000000  49.000000\n",
       "mean   65.646538  59.476446  62.136173  71.767340  69.190404  70.146273\n",
       "std    4.583137   6.943285   4.645253   5.405378   7.880614   5.195892 \n",
       "min    49.976927  32.571429  39.439184  51.776650  35.926993  42.419660\n",
       "25%    63.913558  56.842105  61.035156  68.916936  67.114954  70.258621\n",
       "50%    65.352697  60.240602  62.944162  72.428627  70.797310  71.240962\n",
       "75%    68.642906  64.721805  65.055874  74.470944  74.671790  72.688525\n",
       "max    73.751135  69.744361  66.863446  82.061762  79.987192  74.963913"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_r_f1_orig_enhanced_as_df(combined_df,\n",
    "                                 split=\"test\",\n",
    "                                 models=list(ENSEMBLE_MODEL_NAME_MAP.keys()),\n",
    "                                 model_name_map=ENSEMBLE_MODEL_NAME_MAP).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
